batch_size: 32
seq_len: 720
predict_len: 96
do_eval: True
epoch: 50


dataset: 
  name: ETTm1
  split:
    train: [0, 34560]  # 12 * 30 * 24
    val: [34560, 46080]  # [12 * 30 * 24 - seq_len, 12 * 30 * 24 + 4 * 30 * 24]
    test: [46080, 57600] # [12 * 30 * 24 + 4 * 30 * 24 - seq_len, 12 * 30 * 24 + 8 * 30 * 24]
  use_holiday: True

model: 
  name: TiDE
  model_cfg:
    c_in: 7
    num_encoder_layers: 1
    use_revin: False
    drop_prob: 0.5
    hidden_size: 1024
    decoder_output_dim: 8
    temporal_decoder_hidden: 128
    optimizer_params:
      learning_rate: 0.000084
      gamma: 0.5
    patience: 10
    #pretrain: non-station_torch.pdparams

test:
  stride: 1

  



