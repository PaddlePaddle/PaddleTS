batch_size: 32
seq_len: 96
predict_len: 720
do_eval: True
epoch: 10


dataset: 
  name: Exchange
  split:
    train: [0, 5311]  # 12 * 30 * 24
    val: [5311, 6071]  # [12 * 30 * 24 - seq_len, 12 * 30 * 24 + 4 * 30 * 24]
    test: [6071, 7588] # [12 * 30 * 24 + 4 * 30 * 24 - seq_len, 12 * 30 * 24 + 8 * 30 * 24]


model: 
  name: Nonstationary_Transformer
  model_cfg:
    c_in: 8
    factor: 3
    p_hidden_dims: [16, 16]
    p_hidden_layers: 2
    optimizer_params:
      learning_rate: 0.0001
      gamma: 0.5
    patience: 5
    #pretrain: non-station_torch.pdparams

test:
  stride: 1

  



