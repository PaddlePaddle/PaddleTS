batch_size: 32
seq_len: 96
predict_len: 720
do_eval: True
epoch: 10


dataset: 
  name: ECL
  split:
    train: [0, 18412]  # 12 * 30 * 24
    val: [18412, 21044]  # [12 * 30 * 24 - seq_len, 12 * 30 * 24 + 4 * 30 * 24]
    test: [21044, 26304] # [12 * 30 * 24 + 4 * 30 * 24 - seq_len, 12 * 30 * 24 + 8 * 30 * 24]


model: 
  name: Nonstationary_Transformer
  model_cfg:
    c_in: 321
    factor: 3
    p_hidden_dims: [256, 256]
    optimizer_params:
      learning_rate: 0.0001
      gamma: 0.5
    patience: 5
    #pretrain: non-station_torch.pdparams

test:
  stride: 1

  



