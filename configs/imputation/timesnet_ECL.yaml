batch_size: 16 #
seq_len: 96 #
predict_len: 0 #
label_len: 0 #
do_eval: True #
epoch: 10 # max_epochs
training: True # 
eval_metrics: ["mae", "mse"] # 
anomaly_ratio: Null

lr_scheduler: # 
  name: Type1Decay
  lr_cfg:
    learning_rate: 0.001
    last_epoch: 0

dataset: 
  name: ECL
  split:
    train: [0, 18412]  # 12 * 30 * 24
    val: [18412, 21044]  # [12 * 30 * 24 - seq_len, 12 * 30 * 24 + 4 * 30 * 24]
    test: [21044, 26304] # [12 * 30 * 24 + 4 * 30 * 24 - seq_len, 12 * 30 * 24 + 8 * 30 * 24]

model: 
  name: TimesNetModel
  model_cfg:
    task_name: imputation
    enc_in: 321 #
    c_out: 321 #
    e_layers: 2 #
    num_kernels: 6 #
    d_model: 64 #
    d_ff: 64 #
    add_transformed_datastamp: True # 
    need_date_in_network: True # 
    top_k: 3 # 
    window_sampling_limit: Null # 
    renorm: Null # 
    drop_last: True #

Loss: mse # or smape or CE

test:
  stride: 1 # 

output: 'output/'